# .github/workflows/build_gfs_250mb.yml
name: Build GFS 250mb Wind Tiles

on:
  workflow_dispatch:
  schedule:
    - cron: '0 */6 * * *'

permissions:
  contents: write

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Install system tools
        run: |
          sudo apt-get update
          sudo apt-get install -y gdal-bin

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install Python dependencies
        run: |
          pip install numpy xarray cfgrib eccodes rasterio matplotlib requests

      - name: Download latest available GFS f000 (00Z/12Z) + set VALID_UTC
        run: |
          set -e
          mkdir -p data

          try_fetch () {
            local ymd="$1"
            local cyc="$2"
            local url="https://nomads.ncep.noaa.gov/pub/data/nccf/com/gfs/prod/gfs.${ymd}/${cyc}/atmos/gfs.t${cyc}z.pgrb2.0p25.f000"
            echo "Trying ${ymd} ${cyc}Z -> ${url}"

            if curl -fsSL --max-time 120 -o data/gfs.grib2 "${url}"; then
              local sz
              sz=$(stat -c%s data/gfs.grib2 || echo 0)
              if [ "${sz}" -gt 2000000 ]; then
                echo "Downloaded OK (${sz} bytes)"
                echo "VALID_UTC=${ymd}${cyc}" >> $GITHUB_ENV
                return 0
              else
                echo "Downloaded file too small (${sz}) - treating as failure"
              fi
            fi

            rm -f data/gfs.grib2
            return 1
          }

          NOW_H=$(date -u +"%H")
          TODAY=$(date -u +"%Y%m%d")
          YDAY=$(date -u -d "yesterday" +"%Y%m%d")

          if [ "${NOW_H}" -ge 18 ]; then
            CANDIDATES="${TODAY}:12 ${TODAY}:00 ${YDAY}:12 ${YDAY}:00"
          elif [ "${NOW_H}" -ge 6 ]; then
            CANDIDATES="${TODAY}:00 ${YDAY}:12 ${YDAY}:00"
          else
            CANDIDATES="${YDAY}:12 ${YDAY}:00"
          fi

          for pair in ${CANDIDATES}; do
            ymd="${pair%%:*}"
            cyc="${pair##*:}"
            if try_fetch "${ymd}" "${cyc}"; then
              break
            fi
          done

          if [ ! -f data/gfs.grib2 ]; then
            echo "ERROR: Could not download any candidate GFS f000 GRIB2."
            exit 2
          fi

          echo "Using VALID_UTC=${VALID_UTC}"

      - name: Generate COLOR 250mb wind GeoTIFF (vmax=225, clipped to WebMercator lat range)
        run: |
          python << 'EOF'
          import xarray as xr
          import numpy as np
          import rasterio
          from rasterio.transform import from_origin
          import matplotlib
          matplotlib.use("Agg")
          import matplotlib.pyplot as plt

          # Web Mercator is only valid to about ±85.0511°
          WEBMERC_MAXLAT = 85.0511

          # Force isobaricInhPa so cfgrib doesn't choke on multiple u/v fields
          ds_u = xr.open_dataset(
              "data/gfs.grib2",
              engine="cfgrib",
              backend_kwargs={
                  "filter_by_keys": {"typeOfLevel": "isobaricInhPa", "shortName": "u"},
                  "indexpath": ""
              },
          )
          ds_v = xr.open_dataset(
              "data/gfs.grib2",
              engine="cfgrib",
              backend_kwargs={
                  "filter_by_keys": {"typeOfLevel": "isobaricInhPa", "shortName": "v"},
                  "indexpath": ""
              },
          )

          u = ds_u["u"].sel(isobaricInhPa=250)
          v = ds_v["v"].sel(isobaricInhPa=250)

          # Wind speed in kt
          speed = np.sqrt(u**2 + v**2) * 1.94384

          # shift lon to -180..180 and sort
          speed = speed.assign_coords(
              longitude=(((speed.longitude + 180) % 360) - 180)
          ).sortby("longitude").sortby("latitude", ascending=False)

          # CLIP to avoid invalid latitude in web mercator reprojection
          speed = speed.sel(latitude=slice(WEBMERC_MAXLAT, -WEBMERC_MAXLAT))

          lats = speed.latitude.values
          lons = speed.longitude.values

          dx = float(abs(lons[1] - lons[0]))
          dy = float(abs(lats[1] - lats[0]))
          transform = from_origin(float(lons.min()), float(lats.max()), dx, dy)

          # --- WRITE RAW SPEED GeoTIFF (for RAOB sampling) ---
          with rasterio.open(
              "output_250mb_speed.tif",
              "w",
              driver="GTiff",
              height=speed.shape[0],
              width=speed.shape[1],
              count=1,
              dtype="float32",
              crs="EPSG:4326",
              transform=transform,
              nodata=np.nan,
          ) as dst:
              dst.write(speed.values.astype("float32"), 1)

          # --- MAKE COLORIZED GeoTIFF FOR TILES ---
          vmin, vmax = 20.0, 225.0
          data = np.clip(speed.values, vmin, vmax)
          norm = (data - vmin) / (vmax - vmin)

          cmap = plt.get_cmap("turbo")
          rgb = (cmap(norm)[..., :3] * 255).astype("uint8")

          with rasterio.open(
              "output_250mb_color.tif",
              "w",
              driver="GTiff",
              height=rgb.shape[0],
              width=rgb.shape[1],
              count=3,
              dtype="uint8",
              crs="EPSG:4326",
              transform=transform,
          ) as dst:
              dst.write(rgb[:, :, 0], 1)
              dst.write(rgb[:, :, 1], 2)
              dst.write(rgb[:, :, 2], 3)

          print("GeoTIFFs written successfully (speed + color)")
          EOF

      - name: Generate map tiles (zoom 0-4)
        run: |
          rm -rf tiles/250mb/latest
          mkdir -p tiles/250mb/latest
          gdal2tiles.py --profile=mercator --xyz -r bilinear -z 0-4 \
            output_250mb_color.tif tiles/250mb/latest

          date > tiles/250mb/latest/last_update.txt

      # --- ADDITION #1: debug + detect where your obs input file actually is ---
      - name: Debug + detect RAOB obs input file
        run: |
          set -e

          echo "=== ls -lah data/raob ==="
          ls -lah data/raob || true

          echo "=== find obs-like files under data/ (maxdepth 4) ==="
          find data -maxdepth 4 -type f \( -iname "*obs*.json" -o -iname "*obs*.csv" \) -print || true

          # Priority order: dedicated obs files first
          SEL=""
          if [ -f data/raob/obs_latest.json ]; then
            SEL="data/raob/obs_latest.json"
          elif [ -f data/raob/obs_latest.csv ]; then
            SEL="data/raob/obs_latest.csv"
          elif [ -f data/raob/latest_obs.csv ]; then
            SEL="data/raob/latest_obs.csv"
          fi

          if [ -n "${SEL}" ] && [ -f "${SEL}" ]; then
            echo "OBS_IN=${SEL}" >> $GITHUB_ENV
            echo "Selected OBS_IN=${SEL}"
          else
            echo "OBS_IN=" >> $GITHUB_ENV
            echo "Selected OBS_IN=<none>"
            echo "NOTE: No dedicated obs_latest.(json|csv) file exists; RAOB obs pipeline is not updating."
          fi

      # --- ADDITION #2: pass --in explicitly (and pass the GFS speed tif explicitly) ---
      - name: Build RAOB 250mb dataset (apples-to-apples)
        env:
          VALID_UTC: ${{ env.VALID_UTC }}
          OBS_IN: ${{ env.OBS_IN }}
        run: |
          set -e
          if [ -z "${OBS_IN}" ] || [ ! -f "${OBS_IN}" ]; then
            echo "ERROR: No RAOB obs input file found. See the previous Debug step output."
            exit 2
          fi

          python scripts/build_raob_250mb_dataset.py \
            --in "${OBS_IN}" \
            --gfs-tif output_250mb_speed.tif \
            --gfs-units kt

      - name: Commit updated tiles and RAOB data
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          git add tiles/250mb/latest tiles/250mb/latest/last_update.txt data/raob/latest.json || true
          git commit -m "Update GFS 250mb tiles + RAOB dataset ($VALID_UTC)" || echo "No changes"
          git push
